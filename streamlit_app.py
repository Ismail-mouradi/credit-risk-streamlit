# -*- coding: utf-8 -*-
"""streamlit_app.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1M0gY5vmJM_Od6sB1JYtAb_ZEl99MF4uz
"""

# ===========================================================
# FULL SHAP INTERPRETABILITY SECTION (ADVANCED)
# ===========================================================

import shap
shap.initjs()

def prettify_feature_name(name):
    """Turn encoded feature names into human-readable labels."""
    base_map = {
        "person_age": "Age",
        "person_income": "Income",
        "person_emp_length": "Employment Length",
        "cb_person_cred_hist_length": "Credit History Length",
        "loan_grade": "Loan Grade",
        "loan_amnt": "Loan Amount",
        "loan_int_rate": "Interest Rate",
        "loan_percent_income": "Loan % Income (DTI)",
        "cb_person_default_on_file": "Previous Default",
    }

    if name in base_map:
        return base_map[name]

    if name.startswith("person_home_ownership_"):
        return f"Home Ownership: {name.split('person_home_ownership_')[1]}"

    if name.startswith("loan_intent_"):
        return f"Loan Intent: {name.split('loan_intent_')[1]}"

    return name  # fallback


# ----------------------- COMPUTE SHAP -------------------------
st.markdown("<div class='block'>", unsafe_allow_html=True)
st.subheader("üîç SHAP Explainability ‚Äî Why This Prediction?")

shap_values = explainer.shap_values(X)

# XGBoost sometimes returns list: [class0, class1]
if isinstance(shap_values, list):
    shap_row = shap_values[1][0]
    base_value = explainer.expected_value[1]
else:
    shap_row = shap_values[0]
    base_value = explainer.expected_value

# Build DataFrame
shap_df = pd.DataFrame({
    "feature": X.columns,
    "value": X.iloc[0],
    "shap": shap_row,
    "abs_shap": np.abs(shap_row)
})

shap_df["pretty"] = shap_df["feature"].apply(prettify_feature_name)
shap_df = shap_df.sort_values("abs_shap", ascending=False)


# ===========================================================
# 1) ‚≠ê BEAUTIFUL SEABORN BARPLOT (TOP 10 IMPACT FEATURES)
# ===========================================================
topN = 10
top_df = shap_df.head(topN).copy()
top_df["color"] = top_df["shap"].apply(lambda v: "#ef4444" if v > 0 else "#3b82f6")

plt.figure(figsize=(8, 5))
sns.barplot(data=top_df, y="pretty", x="shap", palette=top_df["color"])
plt.axvline(0, color="black", linewidth=1)
plt.title("Top Factors Influencing Default Risk", fontsize=14)
plt.xlabel("Impact on Risk (SHAP Value)")
plt.ylabel("")
st.pyplot(plt)


# ===========================================================
# 2) ‚≠ê FORCE PLOT (INTERACTIVE)
# ===========================================================
with st.expander("üìä SHAP Force Plot (Interactive)"):
    st.write("Shows how each feature pushes the prediction ‚Üë or ‚Üì.")

    force_html = shap.force_plot(
        base_value,
        shap_row,
        X,
        matplotlib=False,
        feature_names=[prettify_feature_name(f) for f in X.columns]
    )

    shap_html = f"<head>{shap.getjs()}</head><body>{force_html.html()}</body>"
    st.components.v1.html(shap_html, height=300)


# ===========================================================
# 3) ‚≠ê DECISION PLOT
# ===========================================================
with st.expander("üß† SHAP Decision Plot"):
    st.write("Shows each feature‚Äôs cumulative effect on the final prediction.")

    fig_decision = shap.decision_plot(
        base_value,
        shap_row,
        feature_names=[prettify_feature_name(f) for f in X.columns],
        show=False
    )
    st.pyplot(fig_decision)


# ===========================================================
# 4) ‚≠ê WATERFALL PLOT
# ===========================================================
with st.expander("üìâ SHAP Waterfall Plot"):
    st.write("Shows step-by-step how the model arrives at the probability.")

    shap_exp = shap.Explanation(
        values=shap_row,
        base_values=base_value,
        data=X.iloc[0],
        feature_names=[prettify_feature_name(f) for f in X.columns]
    )

    fig_w = shap.waterfall_plot(shap_exp, max_display=12, show=False)
    st.pyplot(fig_w)


# ===========================================================
# 5) ‚≠ê NATURAL LANGUAGE INTERPRETATION (AI STYLE)
# ===========================================================
st.subheader("üìù Risk Interpretation Summary")

# get top contributors
top_pos = shap_df[shap_df["shap"] > 0].head(3)
top_neg = shap_df[shap_df["shap"] < 0].head(3)

explanation = "### üìå Summary of Influential Factors\n\n"

if len(top_pos) > 0:
    explanation += "**Factors Increasing Risk:**\n"
    for _, row in top_pos.iterrows():
        explanation += f"- **{prettify_feature_name(row['feature'])}** increases risk.\n"
else:
    explanation += "No major features strongly increased risk.\n"

explanation += "\n"

if len(top_neg) > 0:
    explanation += "**Factors Decreasing Risk:**\n"
    for _, row in top_neg.iterrows():
        explanation += f"- **{prettify_feature_name(row['feature'])}** reduces risk.\n"
else:
    explanation += "No major features strongly reduced risk.\n"

st.markdown(explanation)

st.markdown("</div>", unsafe_allow_html=True)
